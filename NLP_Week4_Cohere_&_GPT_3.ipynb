{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbooMardiiyah/text-generation-with-gpt-2-3/blob/main/NLP_Week4_Cohere_%26_GPT_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 4: Cohere + GPT-3\n",
        "\n",
        "### What are we building\n",
        "We came a long way these past couple a weeks. We learned how to work with Word Vectors, RNNs and Transformers. Each consequtive week the model improved by ✨a lot✨\n",
        "\n",
        "Now, for our last project we want to encourage you try and implement some ideas you might have had when you joined this course, using one the latest Transformer: GPT-3 or a similar model through Co:here!\n",
        "\n",
        "### Instructions\n",
        "We will provide you some quick pointers to get you started with GPT-3 and also provide ideas that you might try to implement if you are not sure yet what you would like to try.\n",
        "\n",
        "Some suggestions:\n",
        "- https://docs.cohere.ai/prompt-engineering-wiki/\n",
        "- https://docs.cohere.ai/react-generate-example/\n",
        "- https://github.com/elyase/awesome-gpt3\n",
        "- https://www.educative.io/blog/top-uses-gpt-3-deep-learning\n",
        "- https://gpt3demo.com/ \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SFgTZBUYWUyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies\n",
        "\n",
        "✨ Now let's get started! To kick things off, as always, we will install some dependencies."
      ],
      "metadata": {
        "id": "59OmLGSGiUIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.15.0"
      ],
      "metadata": {
        "id": "M7XKspxliQyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d045c8-3c2a-43c6-d5ed-b7d7eb916947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai==0.15.0\n",
            "  Downloading openai-0.15.0.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai==0.15.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai==0.15.0) (4.64.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai==0.15.0) (1.3.5)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai==0.15.0) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai==0.15.0) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai==0.15.0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai==0.15.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai==0.15.0) (2022.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai==0.15.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai==0.15.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai==0.15.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai==0.15.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai==0.15.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai==0.15.0) (1.24.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.15.0-py3-none-any.whl size=50093 sha256=632ee457dd2bd701e02f4ddccd748a4b46a69989a0032df4e926a7a46fe7f8a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/b1/b5/01a94056fd87ef0ed913b2fa6f1161076b730cf1449f579ab7\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.15.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Key\n",
        "We need an API key from OpenAI:\n",
        "- Create an [account](https://beta.openai.com/signup) \n",
        "- Go to this [link](https://beta.openai.com/account/api-keys) to create an API key\n",
        "- Use the secret key as API key\n"
      ],
      "metadata": {
        "id": "e_IpF-woiX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "yIty-nbeiYeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial\n",
        "\n",
        "Below an example of how you could query GPT-3!\n",
        "\n",
        "The [GitHub repo](https://github.com/openai/openai-python) contains more examples, while the [API](https://beta.openai.com/docs/api-reference?lang=python) provides more insight into the available options."
      ],
      "metadata": {
        "id": "5DUMuvlXjp2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please feel free to modify the HParams. More information about the available options can be found [here](https://beta.openai.com/docs/api-reference/completions/create).\n",
        "\n"
      ],
      "metadata": {
        "id": "IHQ5_KE4oCIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HParams: \n",
        "  engine: str = \"ada\"\n",
        "  temperature: float = 0.5\n",
        "  max_tokens: int = 200\n",
        "  top_p: float = 1.0\n",
        "  frequency_penalty: float = 0.52\n",
        "  presence_penalty: float = 0.5\n",
        "  stop: str = \"11.\"\n",
        "\n",
        "\n",
        "class GPT3TextResponse():\n",
        "  def response(self, prompt):\n",
        "    response = openai.Completion.create(\n",
        "      engine=HParams.engine,\n",
        "      prompt=prompt,\n",
        "      temperature=HParams.temperature,\n",
        "      max_tokens=HParams.max_tokens,\n",
        "      top_p=HParams.top_p,\n",
        "      frequency_penalty=HParams.frequency_penalty,\n",
        "      presence_penalty=HParams.presence_penalty,\n",
        "      stop=[HParams.stop]\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "\n",
        "question = \"GPT-3 ideas\\n\\n\\n1. Classifying Reddit posts\\n2. Generating Twitter tweets\\n3.\"\n",
        "\n",
        "gpt3 = GPT3TextResponse().response(question)\n",
        "print(gpt3)"
      ],
      "metadata": {
        "id": "u9gxN6r9jlmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b2f0bc-e9f7-46ed-ca8a-73b585e90d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generating Google+ posts\n",
            "4. Generating Tumblr posts\n",
            "5. Creating Instagram images\n",
            "\n",
            "\n",
            "1. Generating Reddit posts\n",
            "2. Generating Twitter tweets\n",
            "3. Generating Google+ posts\n",
            "\n",
            "\n",
            "1. Generating Tumblr posts\n",
            "2. Creating Instagram images\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✨ Your idea ✨\n",
        "\n",
        "We really want to encourage to try one of your own ideas or take an idea from the previously suggested links and see if you can come up with something (or maybe let GPT-3 help you come up with an idea?).\n",
        "\n",
        "As always, if you have any questions or like to brainstorm about some ideas, we are there to help you!"
      ],
      "metadata": {
        "id": "psAUyRUkpT2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working on it as a separate project :)"
      ],
      "metadata": {
        "id": "LxgVo19Ok9qk"
      }
    }
  ]
}